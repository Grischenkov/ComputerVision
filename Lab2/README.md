# Лабораторная работа №2. Детектирование объектов

## Задание 
Реализовать программу согласно описанию. Можно использовать языки C++ или Python и любые библиотеки, при этом необходимо чтобы вся задача не решалась только с помощью одной встроенной функции. Сравнить качество работы двух вариантов реализации по точности детектирования.

Необходимо реализовать два примитивных детектора объектов на изображении, работающих с помощью поиска эталона на входном изображении.

* Прямой поиск одного изображения на другом - template matching
* Поиск ключевых точек эталона на входном изображении - SIFT

## Теория
* _MatchTemplate_

Функция matchTemplate библиотеки OpenCV пытается найти шаблон на исходном изображении, путём скольжения шаблона и вычисления метрики схожести.

* _SIFT_

Алгоритм SIFT (Scale-invariant feature transform) позволяет сравнивать изображения, подвергнутые таким трансформациям как изменение масштаба, смещение объекта на сцене, повороты камеры или объекта.

Данный алгоритм относится к группе поиска ключевых точек эталона на входном изображении. Такие алгоритмы заменяют изображение моделью — набором его ключевых точек. Особой называется такая точка изображенного объекта, которая с большой долей вероятности будет найдена на другом изображении этого же объекта.

Назовём детектором метод извлечения ключевых точек из изображения. Детектор должен обеспечивать инвариантность нахождения одних и тех же особых точек относительно преобразований изображений. 

Чтобы определить какая ключевая точка одного изображения соответствует ключевой точке другого изображения используют дискрипторы. Дескриптор — идентификатор ключевой точки, выделяющий её из остальной массы особых точек.

Преобразования, относительно которых мы бы хотели получить инвариантность:
1. смещения,
2. поворот,
3. масштаб (один и тот же объект может быть разных размеров на различных изображениях),
4. изменения яркости,
5. изменения положения камеры.

Основным моментом в детектировании особых точек является построение пирамиды гауссианов (Gaussian) и разностей гауссианов (Difference of Gaussian, DoG).

Разностью гауссианов называют изображение, полученное путем попиксельного вычитания одного гауссина исходного изображения из гауссиана с другим радиусом размытия.

Инвариантность относительно масштаба достигается за счет нахождения ключевых точек для исходного изображения, взятого в разных масштабах. Для этого строится пирамида гауссианов: все масштабируемое пространство разбивается на некоторые участки — октавы, причем часть масштабируемого пространства, занимаемого следующей октавой, в два раза больше части, занимаемой предыдущей. К тому же, при переходе от одной октавы к другой делается ресэмплинг изображения, его размеры уменьшаются вдвое. Естественно, что каждая октава охватывает бесконечное множество гауссианов изображения, поэтому строится только некоторое их количество N, с определенным шагом по радиусу размытия. С тем же шагом достраиваются два дополнительных гауссиана (всего получается N+2), выходящие за пределы октавы.

![Alt text](images/sift_describe_1.png?raw=true "SIFT")

Будем считать точку особой, если она является локальным экстремумом разности гауссианов. Для этого необходимо сравнить точку с 26 соседями: 8 точек на её уровне в пирамиде гауссиан и по 9 точек на предыдущем и следующих уровнях пирамиды. Если точка является минимум или максимумом, то она включается в список особы точек.

![Alt text](images/sift_describe_2.png?raw=true "SIFT")

Далее необходимо уточнить положение экстремума. Это делается с помощью многочлена Тейлора второго порядка, взятого в точке вычисленного экстремума.

Затем идёт стадия фильтрации точек: из списка особых точек удаляются те, которые либо имеют низкую контрастность относительно соседних точек, либо сконцентрированы на границах объектов. Для каждой точки считается несколько специальных функций, по значениям которых решается отбрасывать ли точку.

Для каждой ключевой точки вычисляется особая величина – направление ключевой точки. Это необходимо для обеспечения инвариантности алгоритма относительно поворота объекта. Направление ключевой точки – это угол из интервала [0; 359) точки может быть несколько направлений. Для расчёта направления берётся несколько соседних точек и считаются их градиенты. Чаще всего в качестве соседей берётся квадрат 5 на 5 точек (окно), центром которого является выбранная ключевая точка. Для каждой точки считается её градиент и направление градиента.

Конечное направление ключевой точки находится из гистограммы направлений ключевых точек окна. В гистограмме 36 компонент, которые равномерно покрывают весь интервал в 360 градусов. Направление ключевой точки лежит в промежутке, покрываемом максимальной компонентой гистограммы. Если в гистограмме есть ещё компоненты с величинами не меньше 80% от максимальной величины, то они считаются дополнительными направлениями ключевой точки.

В методе SIFT дескриптором является вектор. Как и направление ключевой точки, дескриптор вычисляется на гауссиане, ближайшем по масштабу к ключевой точке, и исходя из градиентов в некотором окне ключевой точки. Перед вычислением дескриптора это окно поворачивают на угол направления ключевой точки, чем и достигается инвариантность относительно поворота.

![Alt text](images/sift_describe_3.png?raw=true "SIFT")

## Реализация
Программа считывает исходное изображение и шаблон. Поскольку оба используемых в работе алгоритма работают с чёрно-белыми изображениями, преобразуем их с учётом этого ограничения.

Реализация с функцией match_template ищет шаблон на монохромном изображении. При успехе мы получаем координаты окна, которое отрисовываем на цветном исходнике.

После применения алгоритма SIFT мы получаем массив дескрипторов и ключевых точек для изображения. Применяем алгоритма для исходного и шаблонного изображений. Затем получим разности между дескриторами путём использования метода match класса BFMatcher (Brute Force Matcher). Возбмём 10 ближайших дескрипторов. По ним определяем точки на исходном и шаблонном изображении, которые "похожи" друг надруга сильнее всего.

## Результаты
MatchTemplate:

![Alt text](images/mt_sample_1.png?raw=true "MatchTemplate")
![Alt text](images/mt_sample_2.png?raw=true "MatchTemplate")
![Alt text](images/mt_sample_3.png?raw=true "MatchTemplate")

SIFT:

![Alt text](images/sift_sample_1.png?raw=true "SIFT")
![Alt text](images/sift_sample_2.png?raw=true "SIFT")
![Alt text](images/sift_sample_3.png?raw=true "SIFT")
![Alt text](images/sift_sample_4.png?raw=true "SIFT")

## Выводы
В результате проделанной работы было реализовано две функции детектирования объектов с применением алгоритмов MatchTemplate и SIFT. По результатам можно рекомендовать использовать алгоритм SIFT для большинства случаев, однако стоит заметить, что его качество можно значительно улучшить, если шаблон будет содержать максимально приближенный детектируемый объект.

## Список используемых источников
* https://habr.com/ru/post/106302/
* https://docs.opencv.org/4.x/d4/dc6/tutorial_py_template_matching.html
* https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html